{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Minimal Bengali Training",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXOXIUyzZdjE",
        "colab_type": "text"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHuGNfOYaOKY",
        "colab_type": "code",
        "outputId": "9e4a422b-12ec-40a7-9275-289ff88b46fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"larswigger\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"####\" # key from the json file\n",
        "!pip install -q kaggle\n",
        "!kaggle datasets download -d larswigger/minimal-bengalipreprocessing\n",
        "!unzip *.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading minimal-bengalipreprocessing.zip to /content\n",
            " 99% 977M/987M [00:16<00:00, 33.4MB/s]\n",
            "100% 987M/987M [00:16<00:00, 61.6MB/s]\n",
            "Archive:  minimal-bengalipreprocessing.zip\n",
            "  inflating: Folded_Train.csv        \n",
            "  inflating: resized_images.npy      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EF4b2IQYcxgd",
        "colab_type": "code",
        "outputId": "e7bd9278-fcf1-4b7e-c146-9baf5f508b14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1NjoQoBlchI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/Bengali/Output\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sR5OnkcZdjM",
        "colab_type": "code",
        "outputId": "3e9c2820-b96b-4d94-b4d2-4ade5a4a9c66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "!pip install pretrainedmodels\n",
        "#!pip install --upgrade efficientnet-pytorch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pretrainedmodels\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/0e/be6a0e58447ac16c938799d49bfb5fb7a80ac35e137547fc6cee2c08c4cf/pretrainedmodels-0.7.4.tar.gz (58kB)\n",
            "\r\u001b[K     |█████▋                          | 10kB 31.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 20kB 39.3MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 30kB 46.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 40kB 51.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 51kB 50.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 10.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (1.4.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (0.5.0)\n",
            "Collecting munch\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (4.28.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->pretrainedmodels) (6.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision->pretrainedmodels) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision->pretrainedmodels) (1.17.5)\n",
            "Building wheels for collected packages: pretrainedmodels\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-cp36-none-any.whl size=60962 sha256=078ff13e8803ad8bba67c30c4113ebbda3448cb52fff44b323c1091438db99b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/df/63/62583c096289713f22db605aa2334de5b591d59861a02c2ecd\n",
            "Successfully built pretrainedmodels\n",
            "Installing collected packages: munch, pretrainedmodels\n",
            "Successfully installed munch-2.5.0 pretrainedmodels-0.7.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "4wPM9rWgZdjV",
        "colab_type": "code",
        "outputId": "8d3d97c2-0e4b-43fc-d7c7-dcba2f1c917c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import pretrainedmodels\n",
        "import albumentations\n",
        "import gc\n",
        "import os\n",
        "from PIL import Image\n",
        "import sklearn.metrics\n",
        "# define constants\n",
        "ORIGINAL_HEIGHT = 137\n",
        "ORIGINAL_WIDTH = 236\n",
        "PROCESSED_HEIGHT = 95\n",
        "PROCESSED_WIDTH = 165\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", DEVICE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR4fyNrwZdjh",
        "colab_type": "text"
      },
      "source": [
        "# Dataset & Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O16vTdCaZdjl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BengaliDataSet:\n",
        "    #static variable, as there is no difference between instances and no use outside of class\n",
        "    memmap = np.memmap(\"/content/resized_images.npy\", mode=\"r\", shape=(200840, PROCESSED_HEIGHT, PROCESSED_WIDTH))\n",
        "    \n",
        "    def __init__(self, folds, validation=False):\n",
        "        tmp = pd.read_csv(\"/content/Folded_Train.csv\")\n",
        "        tmp = tmp[tmp[\"Fold\"].isin(folds)].reset_index(drop=True)\n",
        "        self.image_ids = tmp[\"image_id\"].values.astype(np.int32)\n",
        "        self.root_labels = tmp[\"grapheme_root\"].values.astype(np.uint8)\n",
        "        self.vowel_labels = tmp[\"vowel_diacritic\"].values.astype(np.uint8)\n",
        "        self.consonant_labels = tmp[\"consonant_diacritic\"].values.astype(np.uint8)\n",
        "        if validation == True:\n",
        "            self.transform = albumentations.Compose([albumentations.Normalize(always_apply=True)])\n",
        "        else:\n",
        "            self.transform = albumentations.Compose([albumentations.ShiftScaleRotate(rotate_limit=10),\n",
        "                                                    albumentations.Normalize(always_apply=True)])\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        #get image from disk, get disk index from image_ids first\n",
        "        img = self.memmap[self.image_ids[index]]\n",
        "        #transfer learning only RGB images\n",
        "        img = Image.fromarray(img).convert(\"RGB\")\n",
        "        img = self.transform(image=np.array(img))[\"image\"]\n",
        "        #torchvision has a different channel order\n",
        "        img = np.transpose(img, (2,0,1))\n",
        "        return (torch.tensor(img), \n",
        "                torch.tensor(self.root_labels[index], dtype=torch.long),\n",
        "                torch.tensor(self.vowel_labels[index], dtype=torch.long),\n",
        "                torch.tensor(self.consonant_labels[index], dtype=torch.long)\n",
        "               )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqhAg5FcZdjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = BengaliDataSet([1,2,3,4])\n",
        "valid_data = BengaliDataSet([0], validation=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-UOFN2tZdj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_data,\n",
        "                                           batch_size=64,\n",
        "                                           shuffle=True,\n",
        "                                           num_workers=6)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_data,\n",
        "                                           batch_size=64,\n",
        "                                           shuffle=False,\n",
        "                                           num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqen9zoPZdkE",
        "colab_type": "text"
      },
      "source": [
        "# Model definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS6JTB_ERycK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from efficientnet_pytorch import EfficientNet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJb2lGjFZdkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.transfer_model = pretrainedmodels.__dict__[\"resnet50\"](pretrained=\"imagenet\")\n",
        "        #self.transfer_model = EfficientNet.from_pretrained(\"efficientnet-b3\")\n",
        "\n",
        "        self.root = torch.nn.Linear(2048, 168)\n",
        "        self.vowel = torch.nn.Linear(2048, 11)\n",
        "        self.consonant = torch.nn.Linear(2048, 7)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        x = self.transfer_model.features(x)\n",
        "        #x = self.transfer_model.extract_features(x)\n",
        "        x = torch.nn.functional.adaptive_max_pool2d(x, 1).reshape(batch_size, -1)\n",
        "        \n",
        "        root = self.root(x)\n",
        "        vowel = self.vowel(x)\n",
        "        consonant = self.consonant(x)\n",
        "        return (root, vowel, consonant)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29twK44MZdkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Net()\n",
        "model = model.to(DEVICE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4HzRwt3Zdkg",
        "colab_type": "code",
        "outputId": "5c8fb82a-0c0a-4f57-fe7e-2b810296e136",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (transfer_model): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): None\n",
              "    (last_linear): Linear(in_features=2048, out_features=1000, bias=True)\n",
              "  )\n",
              "  (root): Linear(in_features=2048, out_features=168, bias=True)\n",
              "  (vowel): Linear(in_features=2048, out_features=11, bias=True)\n",
              "  (consonant): Linear(in_features=2048, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLVabvx7Zdkl",
        "colab_type": "text"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIkab5RrZdkp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rand_bbox(size, lam):\n",
        "    W = size[2]\n",
        "    H = size[3]\n",
        "    cut_rat = np.sqrt(1. - lam)\n",
        "    cut_w = np.int(W * cut_rat)\n",
        "    cut_h = np.int(H * cut_rat)\n",
        "\n",
        "    # uniform\n",
        "    cx = np.random.randint(W)\n",
        "    cy = np.random.randint(H)\n",
        "\n",
        "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
        "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
        "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
        "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
        "\n",
        "    return bbx1, bby1, bbx2, bby2\n",
        "def cutmix(data, targets1, targets2, targets3, alpha):\n",
        "    indices = torch.randperm(data.size(0))\n",
        "    shuffled_data = data[indices]\n",
        "    shuffled_targets1 = targets1[indices]\n",
        "    shuffled_targets2 = targets2[indices]\n",
        "    shuffled_targets3 = targets3[indices]\n",
        "\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    bbx1, bby1, bbx2, bby2 = rand_bbox(data.size(), lam)\n",
        "    data[:, :, bbx1:bbx2, bby1:bby2] = data[indices, :, bbx1:bbx2, bby1:bby2]\n",
        "    # adjust lambda to exactly match pixel ratio\n",
        "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (data.size()[-1] * data.size()[-2]))\n",
        "\n",
        "    targets = [targets1, shuffled_targets1, targets2, shuffled_targets2, targets3, shuffled_targets3, lam]\n",
        "    return data, targets\n",
        "\n",
        "def mixup(data, targets1, targets2, targets3, alpha):\n",
        "    indices = torch.randperm(data.size(0))\n",
        "    shuffled_data = data[indices]\n",
        "    shuffled_targets1 = targets1[indices]\n",
        "    shuffled_targets2 = targets2[indices]\n",
        "    shuffled_targets3 = targets3[indices]\n",
        "\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    data = data * lam + shuffled_data * (1 - lam)\n",
        "    targets = [targets1, shuffled_targets1, targets2, shuffled_targets2, targets3, shuffled_targets3, lam]\n",
        "\n",
        "    return data, targets\n",
        "\n",
        "\n",
        "def cutmix_criterion(preds1,preds2,preds3, targets):\n",
        "    targets1, targets2,targets3, targets4,targets5, targets6, lam = targets[0], targets[1], targets[2], targets[3], targets[4], targets[5], targets[6]\n",
        "    criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n",
        "    return lam * criterion(preds1, targets1) + (1 - lam) * criterion(preds1, targets2) + lam * criterion(preds2, targets3) + (1 - lam) * criterion(preds2, targets4) + lam * criterion(preds3, targets5) + (1 - lam) * criterion(preds3, targets6)\n",
        "\n",
        "def mixup_criterion(preds1,preds2,preds3, targets):\n",
        "    targets1, targets2,targets3, targets4,targets5, targets6, lam = targets[0], targets[1], targets[2], targets[3], targets[4], targets[5], targets[6]\n",
        "    criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n",
        "    return lam * criterion(preds1, targets1) + (1 - lam) * criterion(preds1, targets2) + lam * criterion(preds2, targets3) + (1 - lam) * criterion(preds2, targets4) + lam * criterion(preds3, targets5) + (1 - lam) * criterion(preds3, targets6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LbFMIMIZdk0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#modified to search for highest score instead of lowest loss\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Score improved ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
        "        self.val_loss_min = val_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYyl_BlaZdk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_function(output, target):\n",
        "    root_loss = torch.nn.CrossEntropyLoss()(output[0], target[0])\n",
        "    vowel_loss = torch.nn.CrossEntropyLoss()(output[1], target[1])\n",
        "    consonant_loss = torch.nn.CrossEntropyLoss()(output[2], target[2])\n",
        "    return (root_loss, vowel_loss, consonant_loss)\n",
        "\n",
        "def final_loss_function(losses):\n",
        "    return (losses[0]+losses[1]+losses[2]) / 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXuTPB8hZdlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def competition_scores(output, target):\n",
        "    predictions = np.argmax(output[0].cpu().detach(), axis=1)\n",
        "    root_score = sklearn.metrics.recall_score(\n",
        "        target[0], predictions, average='macro')\n",
        "    predictions = np.argmax(output[1].cpu().detach(), axis=1)\n",
        "    vowel_score = sklearn.metrics.recall_score(\n",
        "        target[1], predictions, average='macro')\n",
        "    predictions = np.argmax(output[2].cpu().detach(), axis=1)\n",
        "    consonant_score = sklearn.metrics.recall_score(\n",
        "        target[2], predictions, average='macro')\n",
        "    return (root_score, vowel_score, consonant_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4AQxP1OZdlP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cutout = albumentations.Compose([albumentations.Cutout(always_apply=True)])\n",
        "\n",
        "def train_epoch(dataset, dataloader, model, optimizer, mixup_prob=0.5, mixup_alpha=0.4, cutmix_alpha=0.4):\n",
        "    model.train()\n",
        "    final_loss = 0\n",
        "    for batch_index, (images, root_label, vowel_label, consonant_label) in enumerate(tqdm(dataloader, total=(len(dataset)//dataloader.batch_size))):\n",
        "        \n",
        "        #cutmix/mixup\n",
        "        if np.random.rand()<mixup_prob:\n",
        "                #move to GPU\n",
        "                images = images.to(DEVICE)\n",
        "                root_label = root_label.to(DEVICE)\n",
        "                vowel_label = vowel_label.to(DEVICE)\n",
        "                consonant_label = consonant_label.to(DEVICE)\n",
        "\n",
        "                images, targets = mixup(images, root_label, vowel_label, consonant_label, mixup_alpha)\n",
        "                output1, output2, output3 = model(images)\n",
        "                optimizer_loss = mixup_criterion(output1,output2,output3, targets) \n",
        "        else:\n",
        "            #apply cutout\n",
        "            images = images.numpy()\n",
        "            for idx, img in enumerate(images):\n",
        "               img = np.transpose(img, (1,2,0))\n",
        "               img = cutout(image=img)[\"image\"]\n",
        "               img = np.transpose(img, (2,0,1))\n",
        "               images[idx] = img\n",
        "            #move to GPU\n",
        "            images = torch.tensor(images)\n",
        "            images = images.to(DEVICE)\n",
        "            root_label = root_label.to(DEVICE)\n",
        "            vowel_label = vowel_label.to(DEVICE)\n",
        "            consonant_label = consonant_label.to(DEVICE)\n",
        "            #step\n",
        "            root_pred, vowel_pred, consonant_pred = model(images)\n",
        "            losses = loss_function((root_pred, vowel_pred, consonant_pred), (root_label, vowel_label, consonant_label))\n",
        "            optimizer_loss = final_loss_function(losses)\n",
        "        optimizer.zero_grad()\n",
        "        final_loss+=float(optimizer_loss)\n",
        "        optimizer_loss.backward()\n",
        "        optimizer.step()\n",
        "    batch_count = len(dataset)//dataloader.batch_size\n",
        "    final_loss /= batch_count\n",
        "    return final_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3stIwniVZdlV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def valid_epoch(dataset, dataloader, model):\n",
        "    model.eval()\n",
        "    final_losses = [0,0,0]\n",
        "    predictions = [[],[],[]]\n",
        "    for batch_index, (images, root_label, vowel_label, consonant_label) in enumerate(tqdm(dataloader, total=(len(dataset)//dataloader.batch_size))):\n",
        "        #move to GPU\n",
        "        images = images.to(DEVICE)\n",
        "        root_label = root_label.to(DEVICE)\n",
        "        vowel_label = vowel_label.to(DEVICE)\n",
        "        consonant_label = consonant_label.to(DEVICE)\n",
        "        #prediction\n",
        "        root_pred, vowel_pred, consonant_pred = model(images)\n",
        "        #increment losses\n",
        "        losses = loss_function((root_pred, vowel_pred, consonant_pred), (root_label, vowel_label, consonant_label))\n",
        "        final_losses[0]+=float(losses[0])\n",
        "        final_losses[1]+=float(losses[1])\n",
        "        final_losses[2]+=float(losses[2])\n",
        "        #add predictions\n",
        "        predictions[0].append(np.argmax(root_pred.cpu().detach(), axis=1))\n",
        "        predictions[1].append(np.argmax(vowel_pred.cpu().detach(), axis=1))\n",
        "        predictions[2].append(np.argmax(consonant_pred.cpu().detach(), axis=1))\n",
        "    #take average of scores\n",
        "    batch_count = len(dataset)//dataloader.batch_size\n",
        "    final_losses[0] /= batch_count\n",
        "    final_losses[1] /= batch_count\n",
        "    final_losses[2] /= batch_count\n",
        "    #combine predictions into one array\n",
        "    predictions[0] = np.concatenate(predictions[0], axis=0)\n",
        "    predictions[1] = np.concatenate(predictions[1], axis=0)\n",
        "    predictions[2] = np.concatenate(predictions[2], axis=0)\n",
        "    final_scores = [0,0,0]\n",
        "    final_scores[0] = sklearn.metrics.recall_score(dataset.root_labels, predictions[0], average='macro')\n",
        "    final_scores[1] = sklearn.metrics.recall_score(dataset.vowel_labels, predictions[1], average='macro')\n",
        "    final_scores[2] = sklearn.metrics.recall_score(dataset.consonant_labels, predictions[2], average='macro')\n",
        "    return (final_losses, final_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKvj9vqOZdli",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", patience=5, factor=0.3, verbose=True)\n",
        "early_stopping = EarlyStopping(patience=10, verbose=True)\n",
        "EPOCHS = 30\n",
        "!rm history.csv\n",
        "with open(\"history.csv\", \"a\") as history:\n",
        "    history.write(\"Epoch,Loss,Valid_Loss,Valid_Root_Loss,Valid_Vowel_Loss,Valid_Consonant_Loss,Valid_Score,Valid_Root_Score,Valid_Vowel_Score,Valid_Consonant_Score\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3hXuSosrXJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "backup = torch.load(\"backup.total\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fay5thmcrXTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer.load_state_dict(backup[\"optimizer\"])\n",
        "model.load_state_dict(backup[\"model\"])\n",
        "scheduler.load_state_dict(backup[\"scheduler\"])\n",
        "early_stopping = backup[\"early_stopping\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqVFJuqOdTf8",
        "colab_type": "text"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yFLLgA7Zdlo",
        "colab_type": "code",
        "outputId": "bd90be1d-1d73-45e1-b056-7dbb376686e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    #create data\n",
        "    \"\"\"\n",
        "    valid_fold = epoch % 5\n",
        "    train_data = BengaliDataSet([x for x in range(5) if not x == valid_fold])\n",
        "    valid_data = BengaliDataSet([valid_fold], validation=True)\n",
        "    train_loader = torch.utils.data.DataLoader(train_data,\n",
        "                                           batch_size=64,\n",
        "                                           shuffle=True,\n",
        "                                           num_workers=6)\n",
        "    valid_loader = torch.utils.data.DataLoader(valid_data,\n",
        "                                           batch_size=64,\n",
        "                                           shuffle=False,\n",
        "                                           num_workers=4)\n",
        "    \"\"\"\n",
        "    #print(f\"Epoch {epoch+1}/{EPOCHS}:\")\n",
        "    train_loss = train_epoch(train_data, train_loader, model, optimizer, mixup_prob=0.5)\n",
        "    #print(f\"Loss: {total_loss} Root_Loss: {train_losses[0]} Vowel_Loss: {train_losses[1]} Consonant_Loss: {train_losses[2]}\")\n",
        "    valid_scores = valid_epoch(valid_data, valid_loader, model)\n",
        "    total_valid_loss = final_loss_function(valid_scores[0])\n",
        "    #print(f\"Valid_Loss: {total_valid_loss} Valid_Root_Loss: {valid_scores[0][0]} Valid_Vowel_Loss: {valid_scores[0][1]} Valid_Consonant_Loss: {valid_scores[0][2]}\")\n",
        "    final_score = np.average(valid_scores[1], weights=[2,1,1])\n",
        "    #print(f\"Valid_Score: {final_score} Valid_Root_Score: {valid_scores[1][0]} Valid_Vowel_Score: {valid_scores[1][1]} Valid_Consonant_Score: {valid_scores[1][2]}\")\n",
        "    #Logging data to file\n",
        "    with open(\"history.csv\", \"a\") as history:\n",
        "        history.write(f\"{epoch+1},{train_loss},\")\n",
        "        history.write(f\"{total_valid_loss},{valid_scores[0][0]},{valid_scores[0][1]},{valid_scores[0][2]},\")\n",
        "        history.write(f\"{final_score},{valid_scores[1][0]},{valid_scores[1][1]},{valid_scores[1][2]}\\n\")\n",
        "    #early stopping\n",
        "    early_stopping(final_score, model)\n",
        "    if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "    #learning rate scheduler\n",
        "    scheduler.step(final_score)\n",
        "    #backup every epoch to be able to continue training\n",
        "    torch.save({\n",
        "                \"model\":model.state_dict(),\n",
        "                \"optimizer\":optimizer.state_dict(),\n",
        "                \"scheduler\":scheduler.state_dict(),\n",
        "                \"early_stopping\": early_stopping\n",
        "                },\n",
        "                \"backup.total\")\n",
        "    #cleanup\n",
        "    gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2511it [14:42,  3.49it/s]                          \n",
            "628it [01:03, 10.65it/s]                         \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Score improved (inf --> 0.894087).  Saving model ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2511it [14:44,  3.45it/s]                          \n",
            "628it [01:02, 10.73it/s]                         \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Score improved (0.894087 --> 0.934528).  Saving model ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2511it [14:47,  3.62it/s]                          \n",
            "628it [01:02,  9.97it/s]                         \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Score improved (0.934528 --> 0.935051).  Saving model ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2511it [14:39,  3.40it/s]                          \n",
            "628it [01:03,  9.90it/s]                         \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Score improved (0.935051 --> 0.943959).  Saving model ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2511it [14:42,  3.39it/s]                          \n",
            "628it [01:03,  9.84it/s]                         \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Score improved (0.943959 --> 0.953844).  Saving model ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2511it [14:41,  3.41it/s]                          \n",
            "628it [01:02, 10.01it/s]                         \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EarlyStopping counter: 1 out of 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2511it [14:47,  3.43it/s]                          \n",
            "628it [01:02, 10.76it/s]                         \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Score improved (0.953844 --> 0.955165).  Saving model ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  8%|▊         | 211/2510 [01:14<14:48,  2.59it/s]"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}